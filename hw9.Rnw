\documentclass[11pt]{article}
\usepackage{fullpage,graphicx,float,amsmath,enumitem,hyperref}
\setlist{parsep=5.5pt}
\setlength{\parindent}{0pt}
\setlength{\parskip}{\baselineskip}

\usepackage{fancyhdr}
\pagestyle{fancy}
\lhead{Time Series HW 8}
\rhead{Andrea Mack and Kenny Flagg}
\setlength{\headheight}{18pt}
\setlength{\headsep}{2pt}

\title{Time Series HW 9}
\author{Andrea Mack and Kenny Flagg}
\date{December 7, 2016}

\begin{document}
\maketitle

<<setup, echo = FALSE, message = FALSE, cache = FALSE>>=
library(knitr)
opts_chunk$set(echo = FALSE, comment = NA, fig.align = "center",
               fig.width = 6.5, fig.height = 4, fig.pos = "H",
               size = "footnotesize", dev = "pdf",
               dev.args = list(pointsize = 11))
knit_theme$set("print")

library(xtable)
options(xtable.table.placement = "H", xtable.caption.placement = "top",
        width = 80, scipen = 1, show.signif.stars = FALSE)

library(TSA)
@

{\it A record exists of the ice on and ice off dates for the Baikal Lake in Siberia from 1869 to 1996. We will focus on the duration of ice being present on the lake, which is a count of days for each year. There are no missing values in the time series.}

{\it You can access this data set via:}

<<data, echo = TRUE>>=
bts <- read.csv("baikal.csv", header = TRUE)$Days
@
{\it Note that these are yearly observations and that the response is number of days of ice on the lake in each year. A researcher might be interested in finding some sort of long-term periodic behavior in these results as well as assessing evidence related to a trend.}

\begin{enumerate}

\item%1
{\it Make a nice looking time series plot of the time series.}

<<prob1>>=
plot(bts ~ I(1869:1996), type = "l", main = "Nice-looking time series plot",
     ylab = "Number of Days with Ice", xlab = "Year")
@

\item%2
{\it Fit an ARMA(17,0) using the arima function and describe the roots discussing}
\begin{enumerate}
\item {\it stationarity and}
\item {\it potential quasi-periodicities.}
\end{enumerate}
{\it To help with (b), you should make a table and sort the roots based on the potential QP.}

<<prob2, results = 'asis'>>=

# roots are found by setting 1-phi1x-phi2x^2-...-phipx^p = 0
# modulus is the length of the slope of a line where x = real component and y = complex component

# quasi-period is the number of lags in each period
# it's quasi- because it is random (fn of autocorrelation), so the period has a confidence interval
# quasi-periods try to separate out the overall quasi-periodicity into several components, 
# why there are many of them

# idea: weather has fixed yearly period, but may have random 5-6 quasi-period
############################################
bts.ar17 <- arima(bts, order = c(17, 0, 0))
xtable(data.frame(Estimate = bts.ar17$coef, SE = sqrt(diag(bts.ar17$var.coef))))

roots <- polyroot(c(1, -bts.ar17$coef[-18]))
roots.frame <- data.frame(Root = format(roots, digits = 3),
                          Modulus = Mod(roots),
                          QP = ifelse(zapsmall(Im(roots)) == 0, NA,
                                      2 * pi / abs(Arg(roots))))

roots.frame <- roots.frame[order(roots.frame$QP),]
print(xtable(roots.frame,
             align = "lrrr"), include.rownames = FALSE)
@

All of the roots have modulous $>$ 1, implying that the process is stationary. One root is real, and the remaining roots are complex and form 8 conjugate pairs. The process has components with quasi-periods ranging from of \Sexpr{signif(roots.frame$QP[1], 3)} to \Sexpr{signif(roots.frame$QP[12], 3)} years that may represent true physical quasi-periodicity. Complex roots resulting in quasi-periods of \Sexpr{signif(roots.frame$QP[13], 3)} and \Sexpr{signif(roots.frame$QP[16], 3)} years are also present, but jump quite a bit and may not represent true physical quasi-periodicity.

\item%3
{\it One method for selecting the order of an ARMA model is to use hypothesis tests on the highest order coefficient and drop down if there is no evidence that the coefficients are different from 0. We can also use confidence intervals to do our test by assessing whether our value of interest under the null is inside or outside of the interval. Even though you are using a 95\% confidence interval, you are still doing a 5\% significance level test. The confint function can be used to generate confidence intervals for coefficients from many models in R, including arima-fit models. Fit an AR(18) model and use the confidence interval to discuss the need for the 18th lag in the model. Then repeat the confidence interval of interest for the previous AR(17) model and discuss the similar result -- what does this suggest about the AR(17) model?}

<<prob3, results = 'asis'>>=
bts.ar18 <- arima(bts, order = c(18, 0, 0))
df18 <- data.frame(confint(bts.ar18)[18,])
colnames(df18) <- "Limits AR(18)"
print(xtable(df18, align = "||r|r||"))
@

Zero is within the 95\% confidence interval for the AR(18) term indicating no evidence that it is needed in the model.

<<prob3x, results = 'asis'>>=
df17 <- data.frame(confint(bts.ar17)[17,])
colnames(df17) <- "Limits AR(17)"
print(xtable(df17, align = "||r|r||"))
@

The entire 95\% confidence interval for the AR(17) term is above zero, indicating a strong evidence that the AR(17) term is positive.

\item%4
{\it Report the estimate and 95\% confidence interval for the ``intercept'' that R reports for the AR(17) model. Interpret the estimate and then calculate the actual estimated intercept in the AR(17) model based on the results. Show your work.}

<<prob4, include = FALSE>>=
df17_int <- data.frame(confint(bts.ar17)[18,])
colnames(df17_int) <- "Limits AR(17) Intercept"
print(xtable(df17_int))
summary(bts.ar17)

@

The intercept in the AR(17) model is estimated to be 113.84 with a standard error of 5.54. The associated 95\% confidence interval is from \Sexpr{df17_int[1,]} to \Sexpr{df17_int[2,]} when an AR(17) model was fit. That is, we are 95\% confident the long run mean when there is no autocorrelation present is between \Sexpr{df17_int[1,]} and \Sexpr{df17_int[2,]} days of ice cover a year.

The average number of days ice was on Baikal Lake per year from 1869 to 1996 was estimated {\bf or population data?} to be 113.85 with an associated 95\% confidence interval of \Sexpr{df17_int[1,]} to \Sexpr{df17_int[2,]} days per year. The observed average number of days per year was 113.57, which is very similar to the model estimate.

The model fit was:

$y_{t} = \phi_{0} + \phi_{1}y_{t-1} + ... + \phi_{17}y_{t-17} + e_{t}$

Where $phi_{0} is the intercept reported by ARIMA(17,0,0). Let $E[y_{t}] = \mu$ for all t and t-i.

Then, $\mu = \phi_{0} + \phi_{1}\mu + ... + \phi_{17} + 0$

The intercept that represents the long run mean is then $\mu$ = \frac{\phi_{0}}{1- \phi_{1} - ... - \phi_{17}}$

The actual estimated mean is then:

\Sexpr{round((1-(sum(bts.ar17$coef[1:17])))*(bts.ar17$coef[18]),3)}

{\it Kenny check}: I believe the difference in interpretation comes in as one is the long run average with autocorrelation present, and the other is not.


The binomial model may be more reasonable for the count data in a finite space.

Reference: \url{http://www.stat.pitt.edu/stoffer/tsa2/Rissues.htm}
\item%5
{\it For the AR(17) model (do not re-fit the model), how many of the lower order autoregressive coefficients are not detectably different from 0 in this model using the confidence intervals?}

<<prob5, results = 'asis'>>=
ci.ar17 <- data.frame(coef(bts.ar17), confint(bts.ar17))[-18,]
colnames(ci.ar17) <- c("Estimate", "Lower 95% Limit", "Upper 95% Limit")

# Find which rows have a CI that excludes 0.
not0 <- which(ci.ar17$`Lower 95% Limit` > 0 | ci.ar17$`Upper 95% Limit` < 0)

print(xtable(ci.ar17), add.to.row = list(as.list(not0 - 1), rep("\\bf ", length(not0))))
@

Of the 16 lower order terms, 14 were not detectably different from 0. Those whose 95\% confidence intervals explude zero are bolded in the table above.

\item%6
{\it To explore long-term QP, you have to consider somewhat higher order AR() models. But sometimes we can get similar fits to the time series from mixed ARMA models. Report the ACF, PACF, and EACF and discuss models that are suggested by these results. We will discuss the PACF and EACF in class on Tuesday so bring questions to class on using them.}

<<prob6>>=
par(mfrow = c(1, 2))
acf(bts)
pacf(bts)
eacf(bts)
@

The PACF shows significant lags at 1 and 2, so an AR(2) model, while the EACF suggests an AR(3) model. Because the ACF cuts off after lag 2, it suggests an MA(2) model. 

Altogether, we would suggest starting with an ARMA(2,0) model.

\item%7
{\it Consider taking a first difference in the series and repeating the diagnostics from \#6. Use the diff function to do the differencing.}

<<prob7>>=
par(mfrow = c(1, 2))
dbts <- diff(bts)
TSA::acf(dbts)
pacf(dbts)
eacf(dbts)
@

All three plots indicate an ARMA(0,1) model for the first differences.

\item%8
{\it This should suggest a particular MA model. Fit that model using arima on the differenced series. In other words, use \verb|arima(dbts, order = c(0, 0, q))| where you need to determine q. Write out the estimated model based on the model results both in terms of the differenced series and the original time series.}

<<prob8>>=
bts.ar0ma1 <- arima(bts, order = c(0,0,1))

dbts.ar0ma1 <- arima(dbts, order = c(0,0,1))

@
Original MA(1) model:
$y_{t} = \Sexpr{round(bts.ar0ma1$coef[2],3)} + \Sexpr{round(bts.ar0ma1$coef[1],3)}e_{t-1} + e_{t}$

Differenced MA(1) model:

$y_{diff_{t}} = \Sexpr{round(dbts.ar0ma1$coef[2],3)} + \Sexpr{round(dbts.ar0ma1$coef[1],3)}e_{diff_{t-1}} + e_{diff_{t}}$

\item%9
{\it Report the confidence interval for the intercept from the model in \#8. Discuss what the test using this confidence interval tells you in this model and how it addresses one of the questions of interest to the researcher.}

The estimated 95\% confidence interval for the intercept from the MA(1) model of the data is between  \Sexpr{round(confint(dbts.ar0ma1)[2,1],3)} and \Sexpr{round(confint(dbts.ar0ma1)[2,2],3)}.




\end{enumerate}

\end{document}
